{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc64bc53-ca21-4223-9a18-ef0589e7a08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\trvig\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\trvig\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\trvig\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.66.1)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas tqdm sklearn tensorflow pyaudio librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11df489d-5356-4950-8ecf-1b6e44f23f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trvig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9786876-bbbf-4a32-aa02-347e9378b9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/cv-other-train/sample-069205.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/cv-valid-train/sample-063134.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/cv-other-train/sample-080873.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/cv-other-train/sample-105595.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/cv-valid-train/sample-144613.npy</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename  gender\n",
       "0  data/cv-other-train/sample-069205.npy  female\n",
       "1  data/cv-valid-train/sample-063134.npy  female\n",
       "2  data/cv-other-train/sample-080873.npy  female\n",
       "3  data/cv-other-train/sample-105595.npy  female\n",
       "4  data/cv-valid-train/sample-144613.npy  female"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"voice_csv.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "111e32e5-87f5-4a6d-887d-382716619100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66933</th>\n",
       "      <td>data/cv-valid-train/sample-171098.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66934</th>\n",
       "      <td>data/cv-other-train/sample-022864.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66935</th>\n",
       "      <td>data/cv-valid-train/sample-080933.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66936</th>\n",
       "      <td>data/cv-other-train/sample-012026.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66937</th>\n",
       "      <td>data/cv-other-train/sample-013841.npy</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename gender\n",
       "66933  data/cv-valid-train/sample-171098.npy   male\n",
       "66934  data/cv-other-train/sample-022864.npy   male\n",
       "66935  data/cv-valid-train/sample-080933.npy   male\n",
       "66936  data/cv-other-train/sample-012026.npy   male\n",
       "66937  data/cv-other-train/sample-013841.npy   male"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df1d072-96a2-4cd5-a405-270a58d4c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 66938\n",
      "Total male samples: 33469\n",
      "Total female samples: 33469\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(df)\n",
    "n_male_samples = len(df[df['gender'] == 'male'])\n",
    "n_female_samples = len(df[df['gender'] == 'female'])\n",
    "print(\"Total samples:\", n_samples)\n",
    "print(\"Total male samples:\", n_male_samples)\n",
    "print(\"Total female samples:\", n_female_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22eb8237-425e-499d-b830-acf001d33e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {\n",
    "    \"male\": 1,\n",
    "    \"female\": 0\n",
    "}\n",
    "\n",
    "def load_data(vector_length=128):\n",
    "    \"\"\"A function to load gender recognition dataset from `data` folder\n",
    "    After the second run, this will load from results/features.npy and results/labels.npy files\n",
    "    as it is much faster!\"\"\"\n",
    "\n",
    "    if not os.path.isdir(\"results\"):\n",
    "        os.mkdir(\"results\")\n",
    "    if os.path.isfile(\"results/features.npy\") and os.path.isfile(\"results/labels.npy\"):\n",
    "        X = np.load(\"results/features.npy\")\n",
    "        y = np.load(\"results/labels.npy\")\n",
    "        return X, y\n",
    "   \n",
    "    df = pd.read_csv(\"balanced-all.csv\")\n",
    "    \n",
    "    n_samples = len(df)\n",
    "    \n",
    "    n_male_samples = len(df[df['gender'] == 'male'])\n",
    "    \n",
    "    \n",
    "    n_female_samples = len(df[df['gender'] == 'female'])\n",
    "    print(\"Total samples:\", n_samples)\n",
    "    print(\"Total male samples:\", n_male_samples)\n",
    "    print(\"Total female samples:\", n_female_samples)\n",
    "    X = np.zeros((n_samples, vector_length))\n",
    "    y = np.zeros((n_samples, 1))\n",
    "    for i, (filename, gender) in tqdm.tqdm(enumerate(zip(df['filename'], df['gender'])), \"Loading data\", total=n_samples):\n",
    "        features = np.load(filename)\n",
    "        X[i] = features\n",
    "        y[i] = label2int[gender]\n",
    "    np.save(\"results/features\", X)\n",
    "    np.save(\"results/labels\", y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "886849e8-e845-4fe1-8706-ebc54f36bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.1, valid_size=0.1):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=7)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size, random_state=7)\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_valid\": X_valid,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_valid\": y_valid,\n",
    "        \"y_test\": y_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92c03f45-8ea7-44ca-8bc0-878bc09b7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()\n",
    "data = split_data(X, y, test_size=0.1, valid_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e723b7c8-6e2a-4cf6-b5cd-af345b75e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vector_length=128):\n",
    "    \"\"\"5 hidden dense layers from 256 units to 64, not the best model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(vector_length,)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "505baa5f-9e71-4639-ae19-041d48f68978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\trvig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\trvig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156545 (611.50 KB)\n",
      "Trainable params: 156545 (611.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b134836-6458-4256-aa09-241d792befec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\trvig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\trvig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "848/848 [==============================] - 16s 12ms/step - loss: 0.5723 - accuracy: 0.7665 - val_loss: 0.4032 - val_accuracy: 0.8408\n",
      "Epoch 2/100\n",
      "848/848 [==============================] - 10s 12ms/step - loss: 0.4196 - accuracy: 0.8331 - val_loss: 0.3692 - val_accuracy: 0.8578\n",
      "Epoch 3/100\n",
      "848/848 [==============================] - 9s 11ms/step - loss: 0.3838 - accuracy: 0.8483 - val_loss: 0.3164 - val_accuracy: 0.8798\n",
      "Epoch 4/100\n",
      "848/848 [==============================] - 9s 10ms/step - loss: 0.3646 - accuracy: 0.8565 - val_loss: 0.3300 - val_accuracy: 0.8727\n",
      "Epoch 5/100\n",
      "848/848 [==============================] - 8s 10ms/step - loss: 0.3493 - accuracy: 0.8644 - val_loss: 0.2955 - val_accuracy: 0.8861\n",
      "Epoch 6/100\n",
      "848/848 [==============================] - 9s 10ms/step - loss: 0.3445 - accuracy: 0.8693 - val_loss: 0.2956 - val_accuracy: 0.8856\n",
      "Epoch 7/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.3306 - accuracy: 0.8734 - val_loss: 0.3025 - val_accuracy: 0.8817\n",
      "Epoch 8/100\n",
      "848/848 [==============================] - 10s 12ms/step - loss: 0.3208 - accuracy: 0.8777 - val_loss: 0.2721 - val_accuracy: 0.8876\n",
      "Epoch 9/100\n",
      "848/848 [==============================] - 10s 12ms/step - loss: 0.3103 - accuracy: 0.8803 - val_loss: 0.2622 - val_accuracy: 0.8951\n",
      "Epoch 10/100\n",
      "848/848 [==============================] - 8s 10ms/step - loss: 0.3082 - accuracy: 0.8828 - val_loss: 0.2604 - val_accuracy: 0.8983\n",
      "Epoch 11/100\n",
      "848/848 [==============================] - 8s 10ms/step - loss: 0.3065 - accuracy: 0.8851 - val_loss: 0.2821 - val_accuracy: 0.8911\n",
      "Epoch 12/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2984 - accuracy: 0.8860 - val_loss: 0.2633 - val_accuracy: 0.8949\n",
      "Epoch 13/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2976 - accuracy: 0.8862 - val_loss: 0.2509 - val_accuracy: 0.9041\n",
      "Epoch 14/100\n",
      "848/848 [==============================] - 9s 11ms/step - loss: 0.2979 - accuracy: 0.8889 - val_loss: 0.2564 - val_accuracy: 0.9027\n",
      "Epoch 15/100\n",
      "848/848 [==============================] - 10s 12ms/step - loss: 0.2919 - accuracy: 0.8921 - val_loss: 0.2524 - val_accuracy: 0.9031\n",
      "Epoch 16/100\n",
      "848/848 [==============================] - 10s 11ms/step - loss: 0.2893 - accuracy: 0.8913 - val_loss: 0.2507 - val_accuracy: 0.9001\n",
      "Epoch 17/100\n",
      "848/848 [==============================] - 8s 10ms/step - loss: 0.2861 - accuracy: 0.8932 - val_loss: 0.2475 - val_accuracy: 0.9039\n",
      "Epoch 18/100\n",
      "848/848 [==============================] - 8s 10ms/step - loss: 0.2828 - accuracy: 0.8943 - val_loss: 0.2466 - val_accuracy: 0.9057\n",
      "Epoch 19/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2843 - accuracy: 0.8936 - val_loss: 0.2626 - val_accuracy: 0.9094\n",
      "Epoch 20/100\n",
      "848/848 [==============================] - 8s 10ms/step - loss: 0.2816 - accuracy: 0.8936 - val_loss: 0.2528 - val_accuracy: 0.8984\n",
      "Epoch 21/100\n",
      "848/848 [==============================] - 8s 10ms/step - loss: 0.2829 - accuracy: 0.8929 - val_loss: 0.2446 - val_accuracy: 0.9095\n",
      "Epoch 22/100\n",
      "848/848 [==============================] - 8s 10ms/step - loss: 0.2804 - accuracy: 0.8942 - val_loss: 0.2489 - val_accuracy: 0.9061\n",
      "Epoch 23/100\n",
      "848/848 [==============================] - 11s 13ms/step - loss: 0.2789 - accuracy: 0.8968 - val_loss: 0.2360 - val_accuracy: 0.9140\n",
      "Epoch 24/100\n",
      "848/848 [==============================] - 9s 10ms/step - loss: 0.2740 - accuracy: 0.8977 - val_loss: 0.2437 - val_accuracy: 0.9061\n",
      "Epoch 25/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2756 - accuracy: 0.8958 - val_loss: 0.2395 - val_accuracy: 0.9120\n",
      "Epoch 26/100\n",
      "848/848 [==============================] - 8s 10ms/step - loss: 0.2724 - accuracy: 0.8962 - val_loss: 0.2391 - val_accuracy: 0.9124\n",
      "Epoch 27/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2745 - accuracy: 0.8963 - val_loss: 0.2346 - val_accuracy: 0.9124\n",
      "Epoch 28/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2706 - accuracy: 0.8973 - val_loss: 0.2347 - val_accuracy: 0.9120\n",
      "Epoch 29/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2654 - accuracy: 0.9002 - val_loss: 0.2409 - val_accuracy: 0.9124\n",
      "Epoch 30/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2687 - accuracy: 0.9013 - val_loss: 0.2406 - val_accuracy: 0.9107\n",
      "Epoch 31/100\n",
      "848/848 [==============================] - 9s 10ms/step - loss: 0.2643 - accuracy: 0.9003 - val_loss: 0.2361 - val_accuracy: 0.9130\n",
      "Epoch 32/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2617 - accuracy: 0.9022 - val_loss: 0.2300 - val_accuracy: 0.9137\n",
      "Epoch 33/100\n",
      "848/848 [==============================] - 9s 11ms/step - loss: 0.2643 - accuracy: 0.9016 - val_loss: 0.2271 - val_accuracy: 0.9154\n",
      "Epoch 34/100\n",
      "848/848 [==============================] - 9s 10ms/step - loss: 0.2644 - accuracy: 0.9013 - val_loss: 0.2289 - val_accuracy: 0.9154\n",
      "Epoch 35/100\n",
      "848/848 [==============================] - 9s 10ms/step - loss: 0.2600 - accuracy: 0.9042 - val_loss: 0.2338 - val_accuracy: 0.9119\n",
      "Epoch 36/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2613 - accuracy: 0.9026 - val_loss: 0.2308 - val_accuracy: 0.9124\n",
      "Epoch 37/100\n",
      "848/848 [==============================] - 7s 9ms/step - loss: 0.2611 - accuracy: 0.9017 - val_loss: 0.2331 - val_accuracy: 0.9130\n",
      "Epoch 38/100\n",
      "848/848 [==============================] - 8s 9ms/step - loss: 0.2608 - accuracy: 0.9016 - val_loss: 0.2246 - val_accuracy: 0.9162\n",
      "Epoch 39/100\n",
      "848/848 [==============================] - 8s 10ms/step - loss: 0.2560 - accuracy: 0.9036 - val_loss: 0.2295 - val_accuracy: 0.9137\n",
      "Epoch 40/100\n",
      "848/848 [==============================] - 9s 10ms/step - loss: 0.2582 - accuracy: 0.9028 - val_loss: 0.2381 - val_accuracy: 0.9094\n",
      "Epoch 41/100\n",
      "848/848 [==============================] - 9s 11ms/step - loss: 0.2615 - accuracy: 0.9044 - val_loss: 0.2391 - val_accuracy: 0.9154\n",
      "Epoch 42/100\n",
      "848/848 [==============================] - 9s 10ms/step - loss: 0.2616 - accuracy: 0.9024 - val_loss: 0.2274 - val_accuracy: 0.9170\n",
      "Epoch 43/100\n",
      "848/848 [==============================] - 9s 10ms/step - loss: 0.2546 - accuracy: 0.9046 - val_loss: 0.2183 - val_accuracy: 0.9162\n",
      "Epoch 44/100\n",
      "848/848 [==============================] - 10s 11ms/step - loss: 0.2555 - accuracy: 0.9064 - val_loss: 0.2226 - val_accuracy: 0.9160\n",
      "Epoch 45/100\n",
      "848/848 [==============================] - 9s 11ms/step - loss: 0.2516 - accuracy: 0.9062 - val_loss: 0.2265 - val_accuracy: 0.9157\n",
      "Epoch 46/100\n",
      "848/848 [==============================] - 9s 11ms/step - loss: 0.2546 - accuracy: 0.9050 - val_loss: 0.2191 - val_accuracy: 0.9154\n",
      "Epoch 47/100\n",
      "848/848 [==============================] - 10s 12ms/step - loss: 0.2562 - accuracy: 0.9058 - val_loss: 0.2310 - val_accuracy: 0.9109\n",
      "Epoch 48/100\n",
      "848/848 [==============================] - 10s 12ms/step - loss: 0.2553 - accuracy: 0.9054 - val_loss: 0.2192 - val_accuracy: 0.9162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d9e161afd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir=\"logs\")\n",
    "early_stopping = EarlyStopping(mode=\"min\", patience=5, restore_best_weights=True)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "model.fit(data[\"X_train\"], data[\"y_train\"], epochs=epochs, batch_size=batch_size, validation_data=(data[\"X_valid\"], data[\"y_valid\"]),\n",
    "          callbacks=[tensorboard, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eafd0606-3e78-42fd-9d8d-162bc9d8955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trvig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"results/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fd1b46a-8fff-4486-bb7e-994301c7219f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model using 6694 samples...\n",
      "Loss: 0.2247\n",
      "Accuracy: 91.96%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Evaluating the model using {len(data['X_test'])} samples...\")\n",
    "loss, accuracy = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d52befcc-6ea1-4b85-96dd-67a445add9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15044), started 3 days, 8:06:56 ago. (Use '!kill 15044' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7157086fdb436d9d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7157086fdb436d9d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2bfb5fa-959a-4c83-91fd-aa3d9dc56c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    X, sample_rate = librosa.core.load(file_name)\n",
    "    if chroma or contrast:\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "    result = np.array([])\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, chroma))\n",
    "    if mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, mel))\n",
    "    if contrast:\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, contrast))\n",
    "    if tonnetz:\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aca277a1-a0f0-4eeb-8a46-643235adc621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\trvig\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.14)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3f05165-c8e5-445a-a562-c25eaa3574b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\trvig\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8dbae1b3-0480-4d91-bb69-898b083e3d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_60 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156545 (611.50 KB)\n",
      "Trainable params: 156545 (611.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "No valid WAV file provided. Using default file 'test.wav'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trvig\\AppData\\Local\\Temp\\ipykernel_16920\\4209621172.py:49: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  X, sample_rate = librosa.core.load(file_name)\n",
      "C:\\Users\\trvig\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_directory\\\\test.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[1;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[1;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[0;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'path_to_directory\\\\test.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 86\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid WAV file provided. Using default file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.wav\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m     file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_directory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[34], line 49\u001b[0m, in \u001b[0;36mextract_feature\u001b[1;34m(file_name, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m contrast \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontrast\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m tonnetz \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtonnetz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m X, sample_rate \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chroma \u001b[38;5;129;01mor\u001b[39;00m contrast:\n\u001b[0;32m     51\u001b[0m     stft \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(librosa\u001b[38;5;241m.\u001b[39mstft(X))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[0;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\util\\decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    236\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[0;32m    242\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\audioread\\__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\audioread\\rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_directory\\\\test.wav'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import librosa\n",
    "import audioread\n",
    "import test\n",
    "import utils\n",
    "\n",
    "\n",
    "\n",
    "# Your function to create the model\n",
    "def create_model(vector_length=128):\n",
    "    \"\"\"5 hidden dense layers from 256 units to 64, not the best model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(vector_length,)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model\n",
    "    pass\n",
    "\n",
    "# Your function to extract features\n",
    "\n",
    "def extract_feature(file_name, **kwargs):\n",
    "    \"\"\"\n",
    "    Extract feature from audio file `file_name`\n",
    "        Features supported:\n",
    "            - MFCC (mfcc)\n",
    "            - Chroma (chroma)\n",
    "            - MEL Spectrogram Frequency (mel)\n",
    "            - Contrast (contrast)\n",
    "            - Tonnetz (tonnetz)\n",
    "        e.g:\n",
    "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
    "    \"\"\"\n",
    "    mfcc = kwargs.get(\"mfcc\")\n",
    "    chroma = kwargs.get(\"chroma\")\n",
    "    mel = kwargs.get(\"mel\")\n",
    "    contrast = kwargs.get(\"contrast\")\n",
    "    tonnetz = kwargs.get(\"tonnetz\")\n",
    "    X, sample_rate = librosa.core.load(file_name)\n",
    "    if chroma or contrast:\n",
    "        stft = np.abs(librosa.stft(X))\n",
    "    result = np.array([])\n",
    "    if mfcc:\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "        result = np.hstack((result, mfccs))\n",
    "    if chroma:\n",
    "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, chroma))\n",
    "    if mel:\n",
    "        mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, mel))\n",
    "    if contrast:\n",
    "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, contrast))\n",
    "    if tonnetz:\n",
    "        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "        result = np.hstack((result, tonnetz))\n",
    "    return result\n",
    "    pass\n",
    "parser = argparse.ArgumentParser(description=\"\"\"Gender recognition script, this will load the model you trained, \n",
    "                                    and perform inference on a sample you provide (either using your voice or a file)\"\"\")\n",
    "parser.add_argument(\"-f\", \"--file\", help=\"The path to the file, preferred to be in WAV format\")\n",
    "args = parser.parse_args()\n",
    "file = args.file\n",
    "model = create_model()\n",
    "model.load_weights(\"results/model.h5\")\n",
    "\n",
    "    # You can add more specific error handling if needed\n",
    "\n",
    "# Set a default file if not provided\n",
    "if not file or not os.path.isfile(file) or not file.lower().endswith('.wav'):\n",
    "    print(\"No valid WAV file provided. Using default file 'test.wav'.\")\n",
    "    file = os.path.join(\"path_to_directory\", \"test.wav\")\n",
    "\n",
    "\n",
    "features = extract_feature(file, mel=True)\n",
    "if features is not None:\n",
    "    features = features.reshape(1, -1)\n",
    "else:\n",
    "    print(\"Error extracting features from the file.\")\n",
    "\n",
    "male_prob = model.predict(features)[0][0]\n",
    "female_prob = 1 - male_prob\n",
    "gender = \"male\" if male_prob > female_prob else \"female\"\n",
    "print(\"Result:\", gender)\n",
    "print(f\"Probabilities::: Male: {male_prob*100:.2f}%    Female: {female_prob*100:.2f}%\")\n",
    "print(\"File Path:\", file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "089a498a-bd4a-4d7b-a73b-5fc111f640f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_66 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156545 (611.50 KB)\n",
      "Trainable params: 156545 (611.50 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "Result: male\n",
      "Probabilities:     Male: 78.71%    Female: 21.29%\n"
     ]
    }
   ],
   "source": [
    "%run test.py --file \"test-samples/16-122828-0007.wav\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898554ec-18f2-4cbc-b7d3-4986d73aa83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45247b13-0d56-4622-b7f1-8545ee2968f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
